{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKxypTUyLE7k",
        "outputId": "617d5964-fb46-42e9-9c58-9e7549d0ad14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install biopython\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "from Bio.PDB import PDBParser\n",
        "\n",
        "# 1. Function to extract pLDDT (Confidence)\n",
        "def extract_plddt_from_pdb(pdb_file):\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file)\n",
        "\n",
        "    plddt = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                for atom in residue:\n",
        "                    # pLDDT is stored in the B-factor column of AlphaFold PDBs\n",
        "                    plddt.append(atom.get_bfactor())\n",
        "                    break # We only need one value per residue\n",
        "    return np.array(plddt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Function to load PAE (Error Matrix)\n",
        "def load_pae_from_json(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    # Extract matrix. Shape: [N_res, N_res]\n",
        "    pae_matrix = np.array(data[0]['predicted_aligned_error'])\n",
        "    return pae_matrix\n",
        "\n",
        "# 3. REVISED Function to create Residue-Level Embeddings\n",
        "def create_residue_embedding(plddt, pae, output_pt):\n",
        "    # A. Process PAE: Average the error for each residue\n",
        "    # Shape: [N_res]\n",
        "    pae_mean = np.mean(pae, axis=1)\n",
        "\n",
        "    # B. Combine pLDDT and PAE\n",
        "    # Shape: [N_res, 2]\n",
        "    # We stack them side-by-side\n",
        "    features = np.stack([plddt, pae_mean], axis=1)\n",
        "\n",
        "    # C. Convert to Tensor and Expand to 384 dimensions\n",
        "    # Current shape: [N_res, 2]\n",
        "    x = torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "    # We replicate the 2 features 192 times to get 384 dimensions\n",
        "    # (2 * 192 = 384). Ideally, a Linear layer in the model would do this,\n",
        "    # but we will match your existing input dimension requirement.\n",
        "    x = x.unsqueeze(-1).repeat(1, 1, 192) # Shape: [N_res, 2, 192]\n",
        "    x = x.reshape(x.shape[0], -1)      # Shape: [N_res, 384]\n",
        "\n",
        "    # D. Add Batch Dimension\n",
        "    # Final Shape: [1, N_res, 384]\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    print(f\"Generated embedding shape: {x.shape}\")\n",
        "\n",
        "    # Save ONLY the residue embedding (we don't need global anymore)\n",
        "    torch.save(x, output_pt)\n",
        "    print(f\"Saved to {output_pt}\")"
      ],
      "metadata": {
        "id": "3uJyGk4MMVOl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION BLOCK ---\n",
        "print(\"Processing EGFR...\")\n",
        "egfr_plddt = extract_plddt_from_pdb('AF-P00533-F1-model_v6.pdb')\n",
        "egfr_pae = load_pae_from_json('AF-P00533-F1-predicted_aligned_error_v6.json')\n",
        "create_residue_embedding(egfr_plddt, egfr_pae, 'EGFR_embedding_residue.pt')\n",
        "\n",
        "print(\"\\nProcessing MET...\")\n",
        "met_plddt = extract_plddt_from_pdb('AF-P08581-F1-model_v6.pdb')\n",
        "met_pae = load_pae_from_json('AF-P08581-F1-predicted_aligned_error_v6.json')\n",
        "create_residue_embedding(met_plddt, met_pae, 'MET_embedding_residue.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Y5z3V0Lq50",
        "outputId": "fe01d801-b2d3-4864-a5c0-adcc0c04f126"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing EGFR...\n",
            "Generated embedding shape: torch.Size([1, 1210, 384])\n",
            "Saved to EGFR_embedding_residue.pt\n",
            "\n",
            "Processing MET...\n",
            "Generated embedding shape: torch.Size([1, 1390, 384])\n",
            "Saved to MET_embedding_residue.pt\n"
          ]
        }
      ]
    }
  ]
}